{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T23:57:40.993965Z","iopub.status.busy":"2024-01-10T23:57:40.993666Z","iopub.status.idle":"2024-01-10T23:57:46.896945Z","shell.execute_reply":"2024-01-10T23:57:46.895666Z","shell.execute_reply.started":"2024-01-10T23:57:40.993939Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\LEGION\\anaconda3\\envs\\PRProject\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import math\n","import os\n","import re\n","\n","\n","import nltk\n","import numpy as np\n","import pandas as pd\n","import pyterrier as pt\n","import torch\n","from datasets import load_dataset\n","from sentence_transformers import SentenceTransformer, util, InputExample\n","from sentence_transformers import evaluation\n","from sentence_transformers import models, losses, datasets\n","\n","from torch import nn\n","\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T20:44:57.603891Z","iopub.status.busy":"2024-01-10T20:44:57.603469Z","iopub.status.idle":"2024-01-10T20:44:57.609169Z","shell.execute_reply":"2024-01-10T20:44:57.608310Z","shell.execute_reply.started":"2024-01-10T20:44:57.603865Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.6\n","\n"]},{"name":"stdout","output_type":"stream","text":["Index was loaded successfully from this path:  C:/Users/LEGION/OneDrive - University Of Jordan/GP/quran-qa-2023-main-Task-A/quran-qa-2023-main-Task-A/Task-A/data/QPC_Index/data.properties\n"]}],"source":["def load_index(index_path):\n","    if not pt.started():\n","        pt.init(helper_version=\"0.0.6\")\n","\n","    try:\n","        index = pt.IndexFactory.of(index_path)\n","        print(\"Index was loaded successfully from this path: \", index_path)\n","        return index\n","    except Exception as e:\n","        print('Cannot load the index, check exception details {}'.format(e))\n","        return []\n","index=load_index(\"C:/Users/LEGION/OneDrive - University Of Jordan/GP/quran-qa-2023-main-Task-A/quran-qa-2023-main-Task-A/Task-A/data/QPC_Index/data.properties\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T23:37:13.097002Z","iopub.status.busy":"2024-01-10T23:37:13.096585Z","iopub.status.idle":"2024-01-10T23:37:14.671976Z","shell.execute_reply":"2024-01-10T23:37:14.668601Z","shell.execute_reply.started":"2024-01-10T23:37:13.096969Z"},"trusted":true},"outputs":[],"source":["df_passage=pd.read_csv('../QuestionEncoding/Task A Data/passage.csv')\n","df_query_dev=pd.read_csv('../QuestionEncoding/Task A Data/questionsDev.csv')\n","df_qppair_dev=pd.read_csv('../QuestionEncoding/Task A Data/pairsDev.csv')\n","df_query_train=pd.read_csv('../QuestionEncoding/Task A Data/questionsTrain.csv')\n","df_query_test=pd.read_csv('../QuestionEncoding/Task A Data/questionsTest.csv')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>text</th>\n","      <th>query</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>101</td>\n","      <td>من هم قوم شعيب؟</td>\n","      <td>هم قوم شعيب</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>102</td>\n","      <td>من هم قوم موسى؟</td>\n","      <td>هم قوم موسي</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>103</td>\n","      <td>من بنى الكعبة؟</td>\n","      <td>بني كعبه</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>105</td>\n","      <td>من هو النبي المعروف بالصبر؟</td>\n","      <td>هو نبي معروف صبر</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>106</td>\n","      <td>من كفل السيدة مريم؟</td>\n","      <td>كفل سيد مريم</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>169</th>\n","      <td>422</td>\n","      <td>ما هي الأماكن التي ذُكرت في القرآن كأماكن مقدسة؟</td>\n","      <td>ما هي مكان الذي ذكر قران مكان مقدس</td>\n","    </tr>\n","    <tr>\n","      <th>170</th>\n","      <td>423</td>\n","      <td>لماذا لم يتم حذف الآيات المنسوخة من القرآن؟</td>\n","      <td>لماذا لم تم حذف ايه منسوخ قران</td>\n","    </tr>\n","    <tr>\n","      <th>171</th>\n","      <td>425</td>\n","      <td>هل سيدنا محمد هو أفضل الأنبياء؟</td>\n","      <td>هل سيد محمد هو افضل نبي</td>\n","    </tr>\n","    <tr>\n","      <th>172</th>\n","      <td>426</td>\n","      <td>هل حذر القرآن المؤمنين من اتخاذ أهل الكتاب أول...</td>\n","      <td>هل حذر قران مءمن اتخاذ اهل كتاب ولي ل</td>\n","    </tr>\n","    <tr>\n","      <th>173</th>\n","      <td>427</td>\n","      <td>بأي طريقة حث القرآن المؤمنين على مجادلة أهل ال...</td>\n","      <td>اي طريقه حث قران مءمن مجادله اهل كتاب</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>174 rows × 3 columns</p>\n","</div>"],"text/plain":["     qid                                               text  \\\n","0    101                                    من هم قوم شعيب؟   \n","1    102                                    من هم قوم موسى؟   \n","2    103                                     من بنى الكعبة؟   \n","3    105                        من هو النبي المعروف بالصبر؟   \n","4    106                                من كفل السيدة مريم؟   \n","..   ...                                                ...   \n","169  422   ما هي الأماكن التي ذُكرت في القرآن كأماكن مقدسة؟   \n","170  423        لماذا لم يتم حذف الآيات المنسوخة من القرآن؟   \n","171  425                    هل سيدنا محمد هو أفضل الأنبياء؟   \n","172  426  هل حذر القرآن المؤمنين من اتخاذ أهل الكتاب أول...   \n","173  427  بأي طريقة حث القرآن المؤمنين على مجادلة أهل ال...   \n","\n","                                     query  \n","0                              هم قوم شعيب  \n","1                              هم قوم موسي  \n","2                                 بني كعبه  \n","3                         هو نبي معروف صبر  \n","4                             كفل سيد مريم  \n","..                                     ...  \n","169     ما هي مكان الذي ذكر قران مكان مقدس  \n","170         لماذا لم تم حذف ايه منسوخ قران  \n","171                هل سيد محمد هو افضل نبي  \n","172  هل حذر قران مءمن اتخاذ اهل كتاب ولي ل  \n","173  اي طريقه حث قران مءمن مجادله اهل كتاب  \n","\n","[174 rows x 3 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["df_query_train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T20:44:57.691968Z","iopub.status.busy":"2024-01-10T20:44:57.691621Z","iopub.status.idle":"2024-01-10T20:44:57.713263Z","shell.execute_reply":"2024-01-10T20:44:57.712420Z","shell.execute_reply.started":"2024-01-10T20:44:57.691937Z"},"trusted":true},"outputs":[],"source":["df_passage"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T20:44:57.714511Z","iopub.status.busy":"2024-01-10T20:44:57.714247Z","iopub.status.idle":"2024-01-10T20:44:57.722488Z","shell.execute_reply":"2024-01-10T20:44:57.721603Z","shell.execute_reply.started":"2024-01-10T20:44:57.714488Z"},"trusted":true},"outputs":[],"source":["#Pretraining our bert sentence transformer model\n","def run_simcse(model_name, batch_size, num_epochs, save_name, train_samples_qp_task_B=None):\n","\n","    word_embedding_model = models.Transformer(model_name, max_seq_length=128)\n","    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n","    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n","\n","    train_objectives = []\n","\n","    train_sentences = df_passage['passage'].tolist()\n","\n","    train_data = [InputExample(texts=[s, s]) for s in train_sentences]\n","    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","    train_loss = losses.MultipleNegativesRankingLoss(model)\n","    train_objectives.append((train_dataloader, train_loss))\n","\n","    if train_samples_qp_task_B:\n","        train_samples_qp_task_B_dataloader = DataLoader(train_samples_qp_task_B, batch_size=batch_size, shuffle=True)\n","        constraint_loss = losses.ContrastiveLoss(model)\n","        train_objectives.append((train_samples_qp_task_B_dataloader, constraint_loss))\n","\n","    model.fit(\n","        train_objectives=train_objectives,\n","        epochs=num_epochs)\n","\n","    model_name = os.path.join(f'/kaggle/working/fine_tune/simcse-model-{save_name}')\n","\n","    model.save(model_name)\n","\n","    return model_name"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-10T20:44:57.723974Z","iopub.status.busy":"2024-01-10T20:44:57.723714Z","iopub.status.idle":"2024-01-10T20:44:57.736793Z","shell.execute_reply":"2024-01-10T20:44:57.736054Z","shell.execute_reply.started":"2024-01-10T20:44:57.723951Z"},"trusted":true},"outputs":[],"source":["#Defining our final model structure\n","def build_biencoder(sentence_embedder, max_seq_len):\n","    # Use Huggingface/transformers model (like BERT, RoBERTa, XLNet, XLM-R) for mapping tokens to embeddings\n","    word_embedding_model = models.Transformer(sentence_embedder, max_seq_length=max_seq_len)\n","    print(\"word_embedding_model Max Sequence Length:\", word_embedding_model.max_seq_length)\n","    print(\"word_embedding_model dimension\", word_embedding_model.get_word_embedding_dimension())\n","\n","    # Apply mean pooling to get one fixed sized sentence vector\n","    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n","    print(\"pooling_model sentence embedding dimension\", pooling_model.get_sentence_embedding_dimension())\n","\n","    dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), out_features=512,\n","                               activation_function=nn.Tanh())\n","    bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])\n","\n","    return bi_encoder"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T20:44:57.738297Z","iopub.status.busy":"2024-01-10T20:44:57.738049Z","iopub.status.idle":"2024-01-10T20:44:57.749828Z","shell.execute_reply":"2024-01-10T20:44:57.749009Z","shell.execute_reply.started":"2024-01-10T20:44:57.738275Z"},"trusted":true},"outputs":[],"source":["#Finetuning our model\n","def train_biencoder(bi_encoder, train_objectives, batch_size, num_epochs, warmup_steps):\n","    torch.cuda.empty_cache()\n","\n","    dev_evaluator = evaluation.InformationRetrievalEvaluator(\n","        df_query_dev.groupby('qid')['query'].apply(str).to_dict(),\n","        df_passage.groupby('pid')['passage'].apply(str).to_dict(),\n","        df_qppair_dev.groupby('qid')['docid'].apply(set).to_dict(),\n","        accuracy_at_k=[10],\n","        precision_recall_at_k=[10],\n","        map_at_k=[10], mrr_at_k=[10]\n","    )\n","\n","    # multi-task training\n","    print(\"train_batch_size\", batch_size)\n","    bi_encoder.fit(\n","        train_objectives=train_objectives,\n","        evaluator=dev_evaluator,\n","        epochs=num_epochs,\n","        evaluation_steps=301,\n","        warmup_steps=warmup_steps,\n","        output_path=\"/kaggle/working/fine_tuned_encoder\"\n","    )\n","\n","    return bi_encoder"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T20:44:57.751038Z","iopub.status.busy":"2024-01-10T20:44:57.750776Z","iopub.status.idle":"2024-01-10T20:44:57.759680Z","shell.execute_reply":"2024-01-10T20:44:57.758820Z","shell.execute_reply.started":"2024-01-10T20:44:57.751015Z"},"trusted":true},"outputs":[],"source":["def encode_by_biencoder(encoder):\n","    passage_embeddings = encoder.encode(df_passage['passage'].tolist(), convert_to_tensor=True)\n","    query_train_embeddings = encoder.encode(df_query_train['query'].tolist(), convert_to_tensor=True)\n","    query_dev_embeddings = encoder.encode(df_query_dev['query'].tolist(), convert_to_tensor=True)\n","    query_tset_embeddings = encoder.encode(df_query_test['query'].tolist(), convert_to_tensor=True)\n","\n","    # won't be returned therefore ignored\n","    # df_passage['embedding'] = passage_embeddings.cpu().numpy().tolist()\n","    # df_query_train['embedding'] = query_train_embeddings.cpu().numpy().tolist()\n","    # df_query_dev['embedding'] = query_dev_embeddings.cpu().numpy().tolist()\n","    # df_query_test['embedding'] = query_tset_embeddings.cpu().numpy().tolist()\n","\n","    return passage_embeddings, query_train_embeddings, query_dev_embeddings, query_tset_embeddings"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-01-10T20:44:57.760877Z","iopub.status.busy":"2024-01-10T20:44:57.760615Z","iopub.status.idle":"2024-01-10T22:48:59.189862Z","shell.execute_reply":"2024-01-10T22:48:59.188395Z","shell.execute_reply.started":"2024-01-10T20:44:57.760854Z"},"trusted":true},"outputs":[],"source":["def gym_run2():\n","    model_name = 'distilbert-base-multilingual-cased'\n","    sentence_embedder_name = run_simcse(model_name, batch_size=32, num_epochs=40, save_name=\"run2\")\n","\n","    max_seq_len = 128\n","    bi_encoder = build_biencoder(sentence_embedder_name, max_seq_len)\n","\n","    train_batch_size = 16\n"," \n","    triplets=pd.read_csv('/kaggle/input/dataset1/FarasaDataSet/trainTripletsFarasa.csv')\n","    train_samples_qp_triple =[]\n","    for i in range(len(triplets)):\n","        train_samples_qp_triple.append(InputExample(texts=[triplets['question'].iloc[i],triplets['relPassage'].iloc[i],triplets['irrelPassage'].iloc[i]]))\n","    train_qp_triple_dataloader = DataLoader(train_samples_qp_triple, shuffle=True, batch_size=train_batch_size)\n","\n","    train_biencoder_loss_Triple = losses.TripletLoss(bi_encoder,distance_metric =TripletDistanceMetric.COSINE)\n","\n","    num_epochs = 5\n","    warmup_steps = math.ceil(len(train_qp_triple_dataloader) * num_epochs * 0.1)  #10% of train data for warm-up\n","\n","    train_objectives = [\n","        (train_qp_triple_dataloader, train_biencoder_loss_Triple)\n","    ]\n","    bi_encoder = train_biencoder(bi_encoder, train_objectives, train_batch_size, num_epochs, warmup_steps)\n","    # model_save_path = os.path.join(data_path, f'model/biencoder-simsce-run2')\n","\n","    passage_embeddings, query_train_embeddings, query_dev_embeddings, query_tset_embeddings = encode_by_biencoder(\n","        bi_encoder)\n","\n","\n","    hits = util.semantic_search(query_tset_embeddings, passage_embeddings, top_k=10)\n","    return bi_encoder\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.status.busy":"2024-01-10T22:48:59.191098Z","iopub.status.idle":"2024-01-10T22:48:59.191605Z","shell.execute_reply":"2024-01-10T22:48:59.191362Z","shell.execute_reply.started":"2024-01-10T22:48:59.191338Z"},"trusted":true},"outputs":[],"source":["encoder=SentenceTransformer('../QuestionEncoding/Encoder_Model_run2/',128,device='cuda')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["BM25_model = pt.BatchRetrieve(index, controls={\"wmodel\": \"BM25\"}, num_results=10)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["bm25_biencoder_hit = []\n","\n","for query in df_query_dev['query'].tolist():\n","    bm25_result = BM25_model.search(query)\n","    bm25_related_passage = bm25_result['docno'].tolist()\n","    passage = df_passage[df_passage['pid'].isin(bm25_related_passage)]['passage'].tolist()\n","\n","    try:\n","        query_embedding = encoder.encode(query, convert_to_tensor=True, show_progress_bar=False)\n","        passage_embeddings = encoder.encode(passage, convert_to_tensor=True, show_progress_bar=False)\n","        # TODO\n","        '''\n","        check similarity between query and passage, with methods is better for this task?\n","        util.dot_score\n","        util.cos_sim\n","        util.pairwise_dot_score\n","        util.pairwise_cos_sim\n","        '''\n","        hit = util.semantic_search(query_embedding, passage_embeddings, top_k=10)[0]\n","        mapping = {index: row['docno'] for index, row in bm25_result.iterrows()}\n","\n","    except:\n","        #len passage is 0 but why ?\n","        print(f\"len passage : {len(passage)}, qury : {query}\")\n","        query_embedding = encoder.encode(query, convert_to_tensor=True, show_progress_bar=False)\n","        passage = df_passage['passage'].tolist()\n","        passage_embeddings = encoder.encode(passage, convert_to_tensor=True, show_progress_bar=False)\n","\n","        hit = util.semantic_search(query_embedding, passage_embeddings, top_k=top_k)[0]\n","        mapping = {index: row['pid'] for index, row in df_passage.iterrows()}\n","\n","    for i in range(len(hit)):\n","        hit[i]['corpus_id'] = mapping[hit[i]['corpus_id']]\n","    hit = sorted(hit, key=lambda x: x['score'], reverse=True)\n","    bm25_biencoder_hit.append(hit)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["\n","def save_query_passage_retrieval(result, tag, run_save=False, df_query=df_query_train, top_k=10):\n","    if \"bienc_\" in tag:\n","        np_result = np.array(result).flatten()\n","        result = pd.DataFrame()\n","\n","        result[\"qid\"] = df_query[\"qid\"].tolist() * top_k\n","        result = result.sort_values(by=['qid']).reset_index(drop=True)\n","        result[\"Q0\"] = [\"Q0\"] * len(result)\n","        result[\"pid\"] = [df_passage.iloc[x['corpus_id']]['pid'] for x in np_result]\n","        result[\"rank\"] = list(range(1, top_k + 1)) * len(df_query)\n","        result[\"score\"] = [x['score'] for x in np_result]\n","        result[\"tag\"] = [tag] * len(np_result)\n","\n","    elif tag == \"SimCSE_bmbiencd\":\n","        df_result = pd.DataFrame()\n","        for i in range(len(bm25_biencoder_hit)):\n","            for j in range(len(bm25_biencoder_hit[i])):\n","                new_record = pd.DataFrame([{\"qid\": df_query_dev['qid'].tolist()[i],\n","                                            \"Q0\": \"Q0\",\n","                                            \"pid\": bm25_biencoder_hit[i][j]['corpus_id'],\n","                                            \"rank\": j,\n","                                            \"score\": bm25_biencoder_hit[i][j]['score'],\n","                                            \"tag\": tag\n","                                            }])\n","                df_result = pd.concat([df_result, new_record], ignore_index=True)\n","        result = df_result\n","        print(type(result))\n","\n","    elif tag == \"BM25\":\n","        result[\"Q0\"] = [\"Q0\"] * len(result)\n","        result[\"tag\"] = [tag] * len(result)\n","        result['qid'] = result[\"qid\"]\n","        result['pid'] = result[\"docno\"]\n","        tag = \"BM25_Final\"\n","        result = result[[\"qid\", \"Q0\", \"pid\", \"rank\", \"score\", \"tag\"]]\n","\n","    elif tag == \"biencoder_cross\":\n","        result['tag'] = tag\n","        result['Q0'] = 'Q0'\n","        result = result[[\"qid\", \"Q0\", \"pid\", \"rank\", \"score\", \"tag\"]]\n","\n","    if run_save:\n","        run_save_path = os.path.join(data_path, f\"runs/{tag}.tsv\")\n","        # print(run_save_path)\n","        result.to_csv('results.csv', sep=\"\\t\", index=False, header=False)\n","\n","    return result"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def evaluate_biencoder(query_embeddings, passage_embeddings, df_query, tag):\n","    hits = util.semantic_search(query_embeddings, passage_embeddings, top_k=10)\n","    df_run = save_query_passage_retrieval(hits, tag, run_save=True, df_query=df_query, top_k=10)\n","    return df_run"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["passage_embeddings, query_train_embeddings, query_dev_embeddings, query_tset_embeddings = encode_by_biencoder(encoder)\n","\n","hits = util.semantic_search(query_tset_embeddings, passage_embeddings, top_k=10)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from sentence_transformers.losses import TripletDistanceMetric"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["<function sentence_transformers.losses.TripletLoss.TripletDistanceMetric.<lambda>(x, y)>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["TripletDistanceMetric.COSINE"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["a=[x for x in np_result]"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["a=[x['corpus_id'] for x in a]"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"data":{"text/plain":["520"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["len(a)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/plain":["612       19:1-11\n","659      21:83-86\n","661      21:89-90\n","898      38:41-44\n","829      33:41-44\n","          ...    \n","1233     92:12-21\n","153     3:190-195\n","545      16:35-40\n","1037     52:48-49\n","1116       67:1-5\n","Name: pid, Length: 520, dtype: object"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["df_passage.iloc[[x['corpus_id'] for x in a]]['pid']"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>101</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1735</th>\n","      <td>427</td>\n","    </tr>\n","    <tr>\n","      <th>1736</th>\n","      <td>427</td>\n","    </tr>\n","    <tr>\n","      <th>1737</th>\n","      <td>427</td>\n","    </tr>\n","    <tr>\n","      <th>1738</th>\n","      <td>427</td>\n","    </tr>\n","    <tr>\n","      <th>1739</th>\n","      <td>427</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1740 rows × 1 columns</p>\n","</div>"],"text/plain":["      qid\n","0     101\n","1     101\n","2     101\n","3     101\n","4     101\n","...   ...\n","1735  427\n","1736  427\n","1737  427\n","1738  427\n","1739  427\n","\n","[1740 rows x 1 columns]"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["result[\"qid\"] = df_query_train[\"qid\"].tolist()*10\n","result = result.sort_values(by=['qid']).reset_index(drop=True)\n","result"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Length of values (520) does not match length of index (1740)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_run \u001b[38;5;241m=\u001b[39m save_query_passage_retrieval(hits, tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbienc_train2\u001b[39m\u001b[38;5;124m\"\u001b[39m, df_query\u001b[38;5;241m=\u001b[39mdf_query_train, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      2\u001b[0m df_run\n","Cell \u001b[1;32mIn[10], line 9\u001b[0m, in \u001b[0;36msave_query_passage_retrieval\u001b[1;34m(result, tag, run_save, df_query, top_k)\u001b[0m\n\u001b[0;32m      7\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(result)\n\u001b[1;32m----> 9\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [df_passage\u001b[38;5;241m.\u001b[39miloc[x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorpus_id\u001b[39m\u001b[38;5;124m'\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m np_result]\n\u001b[0;32m     10\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, top_k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_query)\n\u001b[0;32m     11\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m np_result]\n","File \u001b[1;32mc:\\Users\\LEGION\\anaconda3\\envs\\PRProject\\Lib\\site-packages\\pandas\\core\\frame.py:4091\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4088\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4090\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4091\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n","File \u001b[1;32mc:\\Users\\LEGION\\anaconda3\\envs\\PRProject\\Lib\\site-packages\\pandas\\core\\frame.py:4300\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4292\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4293\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4298\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4299\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4300\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m   4302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4303\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4304\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4305\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4306\u001b[0m     ):\n\u001b[0;32m   4307\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n","File \u001b[1;32mc:\\Users\\LEGION\\anaconda3\\envs\\PRProject\\Lib\\site-packages\\pandas\\core\\frame.py:5039\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5039\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\LEGION\\anaconda3\\envs\\PRProject\\Lib\\site-packages\\pandas\\core\\common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Length of values (520) does not match length of index (1740)"]}],"source":["df_run = save_query_passage_retrieval(hits, tag=\"bienc_train2\", df_query=df_query_train, top_k=10)\n","df_run"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["m=re.match('ومن يطع الله والرسول فأولئك مع الذين أنعم الله عليهم','يا أيها الذين آمنوا لا تكونوا كالذين آذوا موسى فبرأه الله مما قالوا وكان عند الله وجيها. يا أيها الذين آمنوا اتقوا الله وقولوا قولا سديدا. يصلح لكم أعمالكم ويغفر لكم ذنوبكم ومن يطع الله ورسوله فقد فاز فوزا عظيما.')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","result[\"pid\"] = [df_passage.iloc[x['corpus_id']]['pid'] for x in np_result]"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["if(m):\n","    print('Lol')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4269126,"sourceId":7364159,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
